{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the data was `wrangled`, the next step is to try and train an artifical neural network model on it. There are many ways to do this, but the quickest and easiest by far is to use `PyTorch`, a wrapper for the Torch algorithm for creating neural networks"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first step in this process is to load in the wrangled data, and separate it into `training`, and `validating` datasets using K-Fold Cross Validation, in order to ensure the network gets a wide array of samples to use."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While we could make our own K-Fold algorithm across the DataFrame, the `skLearn` package makes this process simple, and fast."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PyTorch does not allow for string `tensors`, so we will need to convert our results into a numeric value. Given we are not trying to do any kind of natural language processing, converting to ASCII characters is redundant and overly complex. Instead, we can create a `map` of values, where the key is the string value, and its value is its index in an array. After the model runs, we can index this array at the value to retrieve the key press the model is guessing. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'tuple' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[43], line 25\u001b[0m\n\u001b[1;32m     23\u001b[0m folded_data \u001b[39m=\u001b[39m []\n\u001b[1;32m     24\u001b[0m \u001b[39mfor\u001b[39;00m fold \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(kf\u001b[39m.\u001b[39msplit(eeg_data_raw)):\n\u001b[0;32m---> 25\u001b[0m     \u001b[39mprint\u001b[39m(fold[\u001b[39m1\u001b[39;49m]\u001b[39m.\u001b[39;49mshape)\n\u001b[1;32m     26\u001b[0m     \u001b[39m# result = next(kf.split(eeg_data_raw), None)\u001b[39;00m\n\u001b[1;32m     27\u001b[0m     train \u001b[39m=\u001b[39m eeg_data_raw\u001b[39m.\u001b[39miloc[fold[\u001b[39m0\u001b[39m]]\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'tuple' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "eeg_data_raw = pd.read_csv('eeg_val_to_key_press.csv')\n",
    "\n",
    "eeg_data_raw['KeyPressed'] = eeg_data_raw['KeyPressed'].apply(lambda x: x.lower())\n",
    "\n",
    "unique_res = eeg_data_raw['KeyPressed'].unique()\n",
    "\n",
    "# unique_res\n",
    "\n",
    "res_map = {}\n",
    "\n",
    "for i in range(len(unique_res)):\n",
    "    res_map[unique_res[i]] = i\n",
    "\n",
    "def to_map_val(s):\n",
    "    return res_map[s]\n",
    "\n",
    "eeg_data_raw['KeyPressed'] = eeg_data_raw['KeyPressed'].apply(to_map_val)\n",
    "\n",
    "kf = KFold(n_splits = 5, shuffle = True, random_state = 2)\n",
    "folded_data = []\n",
    "for fold in enumerate(kf.split(eeg_data_raw)):\n",
    "    # result = next(kf.split(eeg_data_raw), None)\n",
    "    train = eeg_data_raw.iloc[fold[0]]\n",
    "    test = eeg_data_raw.iloc[fold[1]]\n",
    "    folded_data.append((train,test))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the train and test dataframes are created, we have to start creating `tensors` from it. To do this, we will extract each of the `EXG` channel values, and use them independently. Then, we will make a `List` of `tensors` and use that as the training dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([263060])\n",
      "torch.Size([8, 263060])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([[  6179.9443,   6184.5264,   6185.8677,  ...,  -1269.0649,\n",
       "           -1265.3993,  -1267.2098],\n",
       "         [  2068.1621,   2071.1350,   2072.3643,  ...,  -3474.9587,\n",
       "           -3476.8586,  -3483.2734],\n",
       "         [ -9348.5498,  -9344.7725,  -9343.8564,  ...,  -9731.5469,\n",
       "           -9737.0908,  -9736.0176],\n",
       "         ...,\n",
       "         [ -1583.4199,  -1581.5647,  -1584.0234,  ...,  -6106.0273,\n",
       "           -6075.4946,  -6087.8774],\n",
       "         [-12547.6660, -12546.4365, -12544.9385,  ..., -13128.3867,\n",
       "          -13130.2861, -13129.5713],\n",
       "         [-13145.9102, -13146.4688, -13149.6875,  ..., -13845.0283,\n",
       "          -13830.8350, -13839.5518]]),\n",
       " tensor([0, 1, 1,  ..., 1, 1, 0], dtype=torch.int8))"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "exg_0 = torch.tensor(train['EXG Channel 0'].values, dtype=torch.float)\n",
    "exg_1 = torch.tensor(train['EXG Channel 1'].values, dtype=torch.float)\n",
    "exg_2 = torch.tensor(train['EXG Channel 2'].values, dtype=torch.float)\n",
    "exg_3 = torch.tensor(train['EXG Channel 3'].values, dtype=torch.float)\n",
    "exg_4 = torch.tensor(train['EXG Channel 4'].values, dtype=torch.float)\n",
    "exg_5 = torch.tensor(train['EXG Channel 5'].values, dtype=torch.float)\n",
    "exg_6 = torch.tensor(train['EXG Channel 6'].values, dtype=torch.float)\n",
    "exg_7 = torch.tensor(train['EXG Channel 7'].values, dtype=torch.float)\n",
    "print(exg_7.shape)\n",
    "train_dataset = torch.stack([exg_0, exg_1, exg_2, exg_3, exg_4, exg_5, exg_6, exg_7])\n",
    "print(train_dataset.shape)\n",
    "y_train = torch.tensor(train['KeyPressed'].values, dtype=torch.int8)\n",
    "\n",
    "train_dataset, y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[  2282.9624,   2273.8652,   2280.7498,  ...,  -1274.2283,\n",
       "           -1271.5237,  -1268.1262],\n",
       "         [ -1207.5753,  -1197.7406,  -1199.0593,  ...,  -3475.6069,\n",
       "           -3472.6565,  -3476.0093],\n",
       "         [-10062.4199, -10060.3418, -10063.2695,  ...,  -9732.3740,\n",
       "           -9733.6709,  -9738.1182],\n",
       "         ...,\n",
       "         [ -3491.2754,  -3518.2764,  -3484.6145,  ...,  -6096.1924,\n",
       "           -6094.2700,  -6073.6621],\n",
       "         [-12830.2139, -12830.6836, -12831.0410,  ..., -13128.1855,\n",
       "          -13130.1299, -13129.9062],\n",
       "         [-13947.5557, -13954.1045, -13937.4521,  ..., -13841.0049,\n",
       "          -13838.3447, -13832.8691]]),\n",
       " tensor([1, 1, 1,  ..., 1, 1, 1], dtype=torch.int8))"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exg_0_test = torch.tensor(test['EXG Channel 0'].values, dtype=torch.float)\n",
    "exg_1_test = torch.tensor(test['EXG Channel 1'].values, dtype=torch.float)\n",
    "exg_2_test = torch.tensor(test['EXG Channel 2'].values, dtype=torch.float)\n",
    "exg_3_test = torch.tensor(test['EXG Channel 3'].values, dtype=torch.float)\n",
    "exg_4_test = torch.tensor(test['EXG Channel 4'].values, dtype=torch.float)\n",
    "exg_5_test = torch.tensor(test['EXG Channel 5'].values, dtype=torch.float)\n",
    "exg_6_test = torch.tensor(test['EXG Channel 6'].values, dtype=torch.float)\n",
    "exg_7_test = torch.tensor(test['EXG Channel 7'].values, dtype=torch.float)\n",
    "\n",
    "test_dataset = torch.stack([exg_0_test, exg_1_test, exg_2_test, exg_3_test, exg_4_test, exg_5_test, exg_6_test, exg_7_test])\n",
    "\n",
    "y_test = torch.tensor(test['KeyPressed'].values, dtype=torch.int8)\n",
    "\n",
    "test_dataset, y_test"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have our sets of `train` and `validate` tensors, as well as their output values, we just need to pass them into the `PyTorch` train method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.utils.data as data_utils\n",
    "\n",
    "#1. make torch.dataset from tensors (or )\n",
    "#2. make dataloader should have 50k\n",
    "#3. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "class EEGDataset(Dataset):\n",
    "    def __init__(self):\n",
    "        eeg_df = pd.read_csv('eeg_val_to_key_press.csv')\n",
    "        eeg_df = eeg_df.drop(['Sample Index', 'Timestamp'], axis=1)\n",
    "        eeg_df['KeyPressed'] = eeg_df['KeyPressed'].apply(lambda x: x.lower())\n",
    "\n",
    "        unique_res = eeg_df['KeyPressed'].unique()\n",
    "\n",
    "        res_map = {}\n",
    "\n",
    "        for i in range(len(unique_res)):\n",
    "            res_map[unique_res[i]] = i\n",
    "\n",
    "        def to_map_val(s):\n",
    "            return res_map[s]\n",
    "\n",
    "        eeg_df['KeyPressed'] = eeg_df['KeyPressed'].apply(to_map_val)\n",
    "\n",
    "        x=eeg_df.iloc[:,0:8].values\n",
    "        y=eeg_df.iloc[:,8].values\n",
    "\n",
    "        self.x_train=torch.tensor(x,dtype=torch.float32)\n",
    "        self.y_train=torch.tensor(y,dtype=torch.float32)\n",
    " \n",
    " \n",
    "    def __len__(self):\n",
    "        return len(self.y_train)\n",
    "    \n",
    "    def __getitem__(self,idx):\n",
    "        return self.x_train[idx],self.y_train[idx]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['Sample Index', 'Timestamp'] not found in axis\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[46], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtorch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdata\u001b[39;00m \u001b[39mimport\u001b[39;00m DataLoader\n\u001b[0;32m----> 3\u001b[0m ds \u001b[39m=\u001b[39m EEGDataset()\n\u001b[1;32m      4\u001b[0m train_loader\u001b[39m=\u001b[39mDataLoader(ds,batch_size\u001b[39m=\u001b[39m\u001b[39m10\u001b[39m,shuffle\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m      6\u001b[0m \u001b[39mfor\u001b[39;00m i, (data, labels) \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(train_loader):\n",
      "Cell \u001b[0;32mIn[45], line 5\u001b[0m, in \u001b[0;36mEEGDataset.__init__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m      4\u001b[0m     eeg_df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mread_csv(\u001b[39m'\u001b[39m\u001b[39meeg_val_to_key_press.csv\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m----> 5\u001b[0m     eeg_df \u001b[39m=\u001b[39m eeg_df\u001b[39m.\u001b[39;49mdrop([\u001b[39m'\u001b[39;49m\u001b[39mSample Index\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mTimestamp\u001b[39;49m\u001b[39m'\u001b[39;49m])\n\u001b[1;32m      6\u001b[0m     eeg_df[\u001b[39m'\u001b[39m\u001b[39mKeyPressed\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m eeg_df[\u001b[39m'\u001b[39m\u001b[39mKeyPressed\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mapply(\u001b[39mlambda\u001b[39;00m x: x\u001b[39m.\u001b[39mlower())\n\u001b[1;32m      8\u001b[0m     unique_res \u001b[39m=\u001b[39m eeg_df[\u001b[39m'\u001b[39m\u001b[39mKeyPressed\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39munique()\n",
      "File \u001b[0;32m~/Documents/School Coding Projects/COGS189_Final_Project/.venv/lib/python3.11/site-packages/pandas/util/_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    325\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(args) \u001b[39m>\u001b[39m num_allow_args:\n\u001b[1;32m    326\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[1;32m    327\u001b[0m         msg\u001b[39m.\u001b[39mformat(arguments\u001b[39m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[1;32m    328\u001b[0m         \u001b[39mFutureWarning\u001b[39;00m,\n\u001b[1;32m    329\u001b[0m         stacklevel\u001b[39m=\u001b[39mfind_stack_level(),\n\u001b[1;32m    330\u001b[0m     )\n\u001b[0;32m--> 331\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/Documents/School Coding Projects/COGS189_Final_Project/.venv/lib/python3.11/site-packages/pandas/core/frame.py:5399\u001b[0m, in \u001b[0;36mDataFrame.drop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   5251\u001b[0m \u001b[39m@deprecate_nonkeyword_arguments\u001b[39m(version\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, allowed_args\u001b[39m=\u001b[39m[\u001b[39m\"\u001b[39m\u001b[39mself\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mlabels\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[1;32m   5252\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdrop\u001b[39m(  \u001b[39m# type: ignore[override]\u001b[39;00m\n\u001b[1;32m   5253\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   5260\u001b[0m     errors: IgnoreRaise \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mraise\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   5261\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m DataFrame \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   5262\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   5263\u001b[0m \u001b[39m    Drop specified labels from rows or columns.\u001b[39;00m\n\u001b[1;32m   5264\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   5397\u001b[0m \u001b[39m            weight  1.0     0.8\u001b[39;00m\n\u001b[1;32m   5398\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 5399\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mdrop(\n\u001b[1;32m   5400\u001b[0m         labels\u001b[39m=\u001b[39;49mlabels,\n\u001b[1;32m   5401\u001b[0m         axis\u001b[39m=\u001b[39;49maxis,\n\u001b[1;32m   5402\u001b[0m         index\u001b[39m=\u001b[39;49mindex,\n\u001b[1;32m   5403\u001b[0m         columns\u001b[39m=\u001b[39;49mcolumns,\n\u001b[1;32m   5404\u001b[0m         level\u001b[39m=\u001b[39;49mlevel,\n\u001b[1;32m   5405\u001b[0m         inplace\u001b[39m=\u001b[39;49minplace,\n\u001b[1;32m   5406\u001b[0m         errors\u001b[39m=\u001b[39;49merrors,\n\u001b[1;32m   5407\u001b[0m     )\n",
      "File \u001b[0;32m~/Documents/School Coding Projects/COGS189_Final_Project/.venv/lib/python3.11/site-packages/pandas/util/_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    325\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(args) \u001b[39m>\u001b[39m num_allow_args:\n\u001b[1;32m    326\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[1;32m    327\u001b[0m         msg\u001b[39m.\u001b[39mformat(arguments\u001b[39m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[1;32m    328\u001b[0m         \u001b[39mFutureWarning\u001b[39;00m,\n\u001b[1;32m    329\u001b[0m         stacklevel\u001b[39m=\u001b[39mfind_stack_level(),\n\u001b[1;32m    330\u001b[0m     )\n\u001b[0;32m--> 331\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/Documents/School Coding Projects/COGS189_Final_Project/.venv/lib/python3.11/site-packages/pandas/core/generic.py:4505\u001b[0m, in \u001b[0;36mNDFrame.drop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   4503\u001b[0m \u001b[39mfor\u001b[39;00m axis, labels \u001b[39min\u001b[39;00m axes\u001b[39m.\u001b[39mitems():\n\u001b[1;32m   4504\u001b[0m     \u001b[39mif\u001b[39;00m labels \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m-> 4505\u001b[0m         obj \u001b[39m=\u001b[39m obj\u001b[39m.\u001b[39;49m_drop_axis(labels, axis, level\u001b[39m=\u001b[39;49mlevel, errors\u001b[39m=\u001b[39;49merrors)\n\u001b[1;32m   4507\u001b[0m \u001b[39mif\u001b[39;00m inplace:\n\u001b[1;32m   4508\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_update_inplace(obj)\n",
      "File \u001b[0;32m~/Documents/School Coding Projects/COGS189_Final_Project/.venv/lib/python3.11/site-packages/pandas/core/generic.py:4546\u001b[0m, in \u001b[0;36mNDFrame._drop_axis\u001b[0;34m(self, labels, axis, level, errors, only_slice)\u001b[0m\n\u001b[1;32m   4544\u001b[0m         new_axis \u001b[39m=\u001b[39m axis\u001b[39m.\u001b[39mdrop(labels, level\u001b[39m=\u001b[39mlevel, errors\u001b[39m=\u001b[39merrors)\n\u001b[1;32m   4545\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 4546\u001b[0m         new_axis \u001b[39m=\u001b[39m axis\u001b[39m.\u001b[39;49mdrop(labels, errors\u001b[39m=\u001b[39;49merrors)\n\u001b[1;32m   4547\u001b[0m     indexer \u001b[39m=\u001b[39m axis\u001b[39m.\u001b[39mget_indexer(new_axis)\n\u001b[1;32m   4549\u001b[0m \u001b[39m# Case for non-unique axis\u001b[39;00m\n\u001b[1;32m   4550\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/Documents/School Coding Projects/COGS189_Final_Project/.venv/lib/python3.11/site-packages/pandas/core/indexes/base.py:6934\u001b[0m, in \u001b[0;36mIndex.drop\u001b[0;34m(self, labels, errors)\u001b[0m\n\u001b[1;32m   6932\u001b[0m \u001b[39mif\u001b[39;00m mask\u001b[39m.\u001b[39many():\n\u001b[1;32m   6933\u001b[0m     \u001b[39mif\u001b[39;00m errors \u001b[39m!=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mignore\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m-> 6934\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlist\u001b[39m(labels[mask])\u001b[39m}\u001b[39;00m\u001b[39m not found in axis\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m   6935\u001b[0m     indexer \u001b[39m=\u001b[39m indexer[\u001b[39m~\u001b[39mmask]\n\u001b[1;32m   6936\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdelete(indexer)\n",
      "\u001b[0;31mKeyError\u001b[0m: \"['Sample Index', 'Timestamp'] not found in axis\""
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "ds = EEGDataset()\n",
    "train_loader=DataLoader(ds,batch_size=10,shuffle=True)\n",
    "\n",
    "for i, (data, labels) in enumerate(train_loader):\n",
    "  print(data.shape, labels.shape)\n",
    "  print(data,labels)\n",
    "  break\n",
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
